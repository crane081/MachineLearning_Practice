{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freqeuntism and Bayesianism: A python-driven Primer\n",
    "### Jake VanderPlas, edited by Crane Huang\n",
    "Reference: http://jakevdp.github.io/blog/2014/06/06/frequentism-and-bayesianism-2-when-results-differ/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. When they are the same: Photon Flux Measurements\n",
    "\n",
    "Imagine that we point a telescope to the sky, and observe the light coming from a single star. Assuming that the star's true photo flux is a fixed value F, and a series of N measurements are perfromed, where the i_th measurement reports the observed flux F_i and error e_i. \n",
    "\n",
    "The question is: given this set of measurements D={F,e}, what is the best esimate of the true flux F?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e=np.random.normal(30,3,50)# generate 50 toy data points: error term.\n",
    "F=np.random.normal(1000,e) # generate 50 toy data points: flux F. (true flux F is 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Frequentist Approach: \n",
    "Maximum Likelihood Estimation (MLE): The result is a simple weighted mean of the observed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001.6444481772371"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w=1./e**2\n",
    "F_hat=np.sum(w*F)/np.sum(w)\n",
    "sigma_F=w.sum() ** -.5\n",
    "F_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Bayesian Approach: \n",
    "\n",
    "P(F|D) = P(D|F)P(F)/P(D) \n",
    "\n",
    "#### Equivalent to Frequentist Approach with a flat prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. When they differ: Bayes' Billiards Game\n",
    "Alice and Bob enter a room to play a game. Carol rolls a ball down the table and marks where it lands. Then Carol begins rolling new balls down the table. If the ball lands to the left of the mark, Alice gets a point; if it lands to the right of the mark, Bob gets a point. The first person to reach 6 points wins the game.\n",
    "\n",
    "In a particular game, after 8 rolls, Alice has 5 points and Bob has 3 points. What is the probability that Bob will 6 points and win the game?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Frequentist Approach: \n",
    "The MLE of P(B)=3/8, and the only senario that Bob can win is to get 3 points in a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Frequentist Probability of Bob winning: 0.05\n"
     ]
    }
   ],
   "source": [
    "p_b_freq=(3/8)**3\n",
    "print(\"Naive Frequentist Probability of Bob winning: %.2f\" %(p_b_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - A Bayesian Approach:\n",
    "#### A beta-binomial distribution, with theta=P(B), prior p(theta|a,b)=Beta(theta|a,b), posterior P(theta|D)~Beta(theta| N1+a, N0+b), where N1=points for Bob, and N0=points for Alice.\n",
    "#### Given a uninformative prior beta (1,1) and likelihood D=(3,5), the posterior predictive prob is Beta(1+6,1+5)/Beta(1+3,1+5); \n",
    "Proof: with prior Beta(1,1) and Likelihood (3,5), we have a posterior distribution of Beta(1+3, 1+5) and can be used as a new prior.\n",
    "For Bob to win, he needs to win 3 games in a row and the data will be D=(3,0), thus P=Beta(3+1+3, 1+5)/Beta(1+3, 1+5), with the posterior distribution Beta(1+3, 1+5) as the new prior. \n",
    "Detailed derivation can be found on P80 in Machine Learning: a probablistic perspective (Kevin Murphy) or on the website provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian posterior probabilty of Bob winning: 0.09\n"
     ]
    }
   ],
   "source": [
    "p_b_bay=beta(1+6,1+5)/beta(1+3,1+5)\n",
    "print(\"Bayesian posterior probabilty of Bob winning: %.2f\" %(p_b_bay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Monte Carlo Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo probability of Bob winning: 0.09\n"
     ]
    }
   ],
   "source": [
    "p = np.random.random(100000) #play 100000 games with randomly-drawn p\n",
    "rolls=np.random.random((11,len(p))) #each game needs at most 11 rolls for one player to reach 6 wins\n",
    "\n",
    "A_count=np.cumsum(rolls<p,0)  #count Alice's total wins at each roll\n",
    "B_count=np.cumsum(rolls>=p,0) #count Bob's total wins at each roll\n",
    "good_games=B_count[7]==3      #determin number of games have (A wins, B wins)=(5,3)\n",
    "A_count=A_count[:,good_games] #keep only suitable games\n",
    "B_count=B_count[:,good_games]\n",
    "\n",
    "B_won=np.sum(B_count[10]==6) #determin which games Bob won\n",
    "\n",
    "mc_prob=B_won/good_games.sum()\n",
    "print(\"Monte Carlo probability of Bob winning: %.2f\" %(mc_prob))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
